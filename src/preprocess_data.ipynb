{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import json\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import re\n",
    "import os\n",
    "import collections\n",
    "import pickle as pkl\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(r'C:\\Users\\anhdq33\\Downloads\\VinBigData\\Deep_Learning\\Project\\fast_abs\\finished_files\\test\\2000.json') as f:\n",
    "#     data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = 'valid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                             summary  \\\n",
       "0   Bản_án cho đối_tượng giả_danh công_an để lừa_đảo   \n",
       "1  Nam thanh_niên thủ_dâm trên xe_buýt từng bị xử...   \n",
       "2  Không được công_nhận , thuốc \" sinh con theo ý...   \n",
       "3  VEC từ_chối phục_vụ vĩnh_viễn 2 ô_tô gây_rối t...   \n",
       "4  VKSND tỉnh Sóc_Trăng xin_lỗi oan sai “ nữ_hoàn...   \n",
       "\n",
       "                                            fullText  \n",
       "0  Ngày 25/2 , TAND TP. Đà_Nẵng tuyên_phạt Hồ_Xuâ...  \n",
       "1  Phát_hiện nam thanh_niên đang thủ_dâm trên xe_...  \n",
       "2  “ Baby_Support ” và “ Hello baby ” là hai cái ...  \n",
       "3  Liên_quan đến vụ gây_rối tại trạm thu phí trên...  \n",
       "4  Bà Huỳnh_Ngọc_Bích được mọi người biết đến là ...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>summary</th>\n      <th>fullText</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Bản_án cho đối_tượng giả_danh công_an để lừa_đảo</td>\n      <td>Ngày 25/2 , TAND TP. Đà_Nẵng tuyên_phạt Hồ_Xuâ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Nam thanh_niên thủ_dâm trên xe_buýt từng bị xử...</td>\n      <td>Phát_hiện nam thanh_niên đang thủ_dâm trên xe_...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Không được công_nhận , thuốc \" sinh con theo ý...</td>\n      <td>“ Baby_Support ” và “ Hello baby ” là hai cái ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>VEC từ_chối phục_vụ vĩnh_viễn 2 ô_tô gây_rối t...</td>\n      <td>Liên_quan đến vụ gây_rối tại trạm thu phí trên...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>VKSND tỉnh Sóc_Trăng xin_lỗi oan sai “ nữ_hoàn...</td>\n      <td>Bà Huỳnh_Ngọc_Bích được mọi người biết đến là ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 59
    }
   ],
   "source": [
    "# df = pd.read_csv(r'C:\\Users\\anhdq33\\Downloads\\VinBigData\\Deep_Learning\\Project\\data\\raw_data\\data\\{}.csv'.format(mode) ,index_col=0)\n",
    "df = pd.read_csv(r'C:\\Users\\anhdq33\\Downloads\\VinBigData\\Deep_Learning\\Project\\data\\{}.csv'.format(mode),index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "source": [
    "# BERTSUM"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def token(text):\n",
    "    text = re.sub('Th .', 'Th.', text)\n",
    "    text = re.sub('\\.', '', text)\n",
    "    text = re.sub('  ', ' . ', text)\n",
    "    para = []\n",
    "    sent_token = sent_tokenize(text)\n",
    "    for sent in sent_token:\n",
    "        word_token = word_tokenize(sent)\n",
    "        para.append(word_token)\n",
    "    return para"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "summary     0\n",
       "fullText    0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "df = df.dropna()\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['fullText_token'] = df['fullText'].apply(lambda text: token(text))\n",
    "df['summary_token'] = df['summary'].apply(lambda text: token(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       index                                            summary  \\\n",
       "22637  22637            TP HCM xây cầu 500 tỷ qua đảo Kim_Cương   \n",
       "22638  22638  Miễn học_phí cho 16.000 học_sinh vùng_biển Quả...   \n",
       "22639  22639  TP HCM yêu_cầu trường công_lập nhận các trẻ bị...   \n",
       "22640  22640  Rơi thang_máy công_trình cao_tầng , 7 người bị...   \n",
       "22641  22641   Nghị_trường mổ_xẻ 5 dự_án nghìn tỷ ' đắp chiếu '   \n",
       "\n",
       "                                                fullText  \\\n",
       "22637  Dài gần 300 m , cầu_nối đại_lộ Mai_Chí_Thọ với...   \n",
       "22638  16.000 học_sinh các cấp ở 4 huyện vùng_biển Qu...   \n",
       "22639  Giám_đốc Sở Giáo_dục TP HCM yêu_cầu các trường...   \n",
       "22640  Máy vận thăng đang từ tầng 6 một công_trình ở ...   \n",
       "22641  Nhiều đại_biểu Quốc_hội bức_xúc vì 5 dự_án ngh...   \n",
       "\n",
       "                                          fullText_token  \\\n",
       "22637  [[Dài, gần, 300, m, ,, cầu_nối, đại_lộ, Mai_Ch...   \n",
       "22638  [[16000, học_sinh, các, cấp, ở, 4, huyện, vùng...   \n",
       "22639  [[Giám_đốc, Sở, Giáo_dục, TP, HCM, yêu_cầu, cá...   \n",
       "22640  [[Máy, vận, thăng, đang, từ, tầng, 6, một, côn...   \n",
       "22641  [[Nhiều, đại_biểu, Quốc_hội, bức_xúc, vì, 5, d...   \n",
       "\n",
       "                                           summary_token  \n",
       "22637  [[TP, HCM, xây, cầu, 500, tỷ, qua, đảo, Kim_Cư...  \n",
       "22638  [[Miễn, học_phí, cho, 16000, học_sinh, vùng_bi...  \n",
       "22639  [[TP, HCM, yêu_cầu, trường, công_lập, nhận, cá...  \n",
       "22640  [[Rơi, thang_máy, công_trình, cao_tầng, ,, 7, ...  \n",
       "22641  [[Nghị_trường, mổ_xẻ, 5, dự_án, nghìn, tỷ, ', ...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>summary</th>\n      <th>fullText</th>\n      <th>fullText_token</th>\n      <th>summary_token</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>22637</th>\n      <td>22637</td>\n      <td>TP HCM xây cầu 500 tỷ qua đảo Kim_Cương</td>\n      <td>Dài gần 300 m , cầu_nối đại_lộ Mai_Chí_Thọ với...</td>\n      <td>[[Dài, gần, 300, m, ,, cầu_nối, đại_lộ, Mai_Ch...</td>\n      <td>[[TP, HCM, xây, cầu, 500, tỷ, qua, đảo, Kim_Cư...</td>\n    </tr>\n    <tr>\n      <th>22638</th>\n      <td>22638</td>\n      <td>Miễn học_phí cho 16.000 học_sinh vùng_biển Quả...</td>\n      <td>16.000 học_sinh các cấp ở 4 huyện vùng_biển Qu...</td>\n      <td>[[16000, học_sinh, các, cấp, ở, 4, huyện, vùng...</td>\n      <td>[[Miễn, học_phí, cho, 16000, học_sinh, vùng_bi...</td>\n    </tr>\n    <tr>\n      <th>22639</th>\n      <td>22639</td>\n      <td>TP HCM yêu_cầu trường công_lập nhận các trẻ bị...</td>\n      <td>Giám_đốc Sở Giáo_dục TP HCM yêu_cầu các trường...</td>\n      <td>[[Giám_đốc, Sở, Giáo_dục, TP, HCM, yêu_cầu, cá...</td>\n      <td>[[TP, HCM, yêu_cầu, trường, công_lập, nhận, cá...</td>\n    </tr>\n    <tr>\n      <th>22640</th>\n      <td>22640</td>\n      <td>Rơi thang_máy công_trình cao_tầng , 7 người bị...</td>\n      <td>Máy vận thăng đang từ tầng 6 một công_trình ở ...</td>\n      <td>[[Máy, vận, thăng, đang, từ, tầng, 6, một, côn...</td>\n      <td>[[Rơi, thang_máy, công_trình, cao_tầng, ,, 7, ...</td>\n    </tr>\n    <tr>\n      <th>22641</th>\n      <td>22641</td>\n      <td>Nghị_trường mổ_xẻ 5 dự_án nghìn tỷ ' đắp chiếu '</td>\n      <td>Nhiều đại_biểu Quốc_hội bức_xúc vì 5 dự_án ngh...</td>\n      <td>[[Nhiều, đại_biểu, Quốc_hội, bức_xúc, vì, 5, d...</td>\n      <td>[[Nghị_trường, mổ_xẻ, 5, dự_án, nghìn, tỷ, ', ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "df = df.reset_index()\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'C:\\Users\\anhdq33\\Downloads\\VinBigData\\Deep_Learning\\Project\\BertSum\\data\\{}'.format(mode)\n",
    "dic = []\n",
    "i = 0\n",
    "for ind, row in df.iterrows():\n",
    "    ind = row['index']\n",
    "    full = row['fullText_token']\n",
    "    summary = row['summary_token']\n",
    "    dic.append({'src': full, 'tgt':summary})\n",
    "    \n",
    "    if (ind+1) % 2000 == 0:\n",
    "        with open(os.path.join(path, 'vnds.{}.{}.json'.format(mode, i)), 'w') as f:\n",
    "            json.dump(dic, f)\n",
    "        i+=1\n",
    "        dic = []\n",
    "    if (ind+1) == len(df):\n",
    "        with open(os.path.join(path, 'vnds.{}.{}.json'.format(mode, i)), 'w') as f:\n",
    "            json.dump(dic, f)"
   ]
  },
  {
   "source": [
    "# fastAbs"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def sent_token(text):\n",
    "#     text = re.sub('Th .', 'Th.', text)\n",
    "#     text = re.sub('\\.', '', text)\n",
    "#     text = re.sub('  ', ' . ', text)\n",
    "#     sent_token = sent_tokenize(text)\n",
    "    \n",
    "#     return sent_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['fullText_token'] = df['fullText'].apply(lambda x: sent_token(x))\n",
    "# df['summary_token'] = df['summary'].apply(lambda x: sent_token(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if mode == 'train':\n",
    "#     vocab_counter = collections.Counter()\n",
    "\n",
    "# path = r'C:\\Users\\anhdq33\\Downloads\\VinBigData\\Deep_Learning\\Project\\data\\fastAbs_data\\{}'.format(mode)\n",
    "# def write_json(row):\n",
    "#     ind = row['index']\n",
    "#     full = row['fullText_token']\n",
    "#     summary = row['summary_token']\n",
    "#     dic = {'id':ind, 'article': full, 'abstract':summary}\n",
    "#     # with open(os.path.join(path, '{}.json'.format(ind)), 'w') as f:\n",
    "#     #     json.dump(dic, f)\n",
    "\n",
    "#     if mode == 'train':\n",
    "#         art_tokens = ' '.join(full).split()\n",
    "#         abs_tokens = ' '.join(summary).split()\n",
    "#         tokens = art_tokens + abs_tokens\n",
    "#         tokens = [t.strip() for t in tokens] # strip\n",
    "#         tokens = [t for t in tokens if t != \"\"] # remove empty\n",
    "#         vocab_counter.update(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.apply(lambda row: write_json(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if mode == 'train':\n",
    "#     print(\"Writing vocab file...\")\n",
    "#     with open(os.path.join(r'C:\\Users\\anhdq33\\Downloads\\VinBigData\\Deep_Learning\\Project\\data\\fastAbs_data', \"vocab_cnt.pkl\"),'wb') as vocab_file:\n",
    "#         pkl.dump(vocab_counter, vocab_file)\n",
    "#     print(\"Finished writing vocab file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %history -g "
   ]
  },
  {
   "source": [
    "# Baseline"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'C:\\Users\\anhdq33\\Downloads\\VinBigData\\Deep_Learning\\Project\\BertSum\\results\\train_step6500.candidate','r', encoding='utf8') as f:\n",
    "    pre = f.readlines()\n",
    "\n",
    "with open(r'C:\\Users\\anhdq33\\Downloads\\VinBigData\\Deep_Learning\\Project\\BertSum\\results\\train_step6500.gold','r', encoding='utf8') as f:\n",
    "    gold = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec = pd.DataFrame(columns=['predict', 'gold'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec['predict'] = pre\n",
    "dec['gold'] = gold\n",
    "dec['predict'] = dec['predict'].apply(lambda x: x.replace('\\n','').replace('<q>',' '))\n",
    "dec['gold'] = dec['gold'].apply(lambda x: x.replace('\\n','').replace('<q>',' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}